{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['00000.png',\n",
       " '00001.png',\n",
       " '00002.png',\n",
       " '00003.png',\n",
       " '00004.png',\n",
       " '00005.png',\n",
       " '00006.png',\n",
       " '00007.png',\n",
       " '00008.png',\n",
       " '00009.png',\n",
       " '00010.png',\n",
       " '00011.png',\n",
       " '00012.png',\n",
       " '00013.png',\n",
       " '00014.png',\n",
       " '00015.png',\n",
       " '00016.png',\n",
       " '00017.png',\n",
       " '00018.png',\n",
       " '00019.png',\n",
       " '00020.png',\n",
       " '00021.png',\n",
       " '00022.png',\n",
       " '00023.png',\n",
       " '00024.png',\n",
       " '00025.png',\n",
       " '00026.png',\n",
       " '00027.png',\n",
       " '00028.png',\n",
       " '00029.png',\n",
       " '00030.png',\n",
       " '00031.png',\n",
       " '00032.png',\n",
       " '00033.png',\n",
       " '00034.png',\n",
       " '00035.png',\n",
       " '00036.png',\n",
       " '00037.png',\n",
       " '00038.png',\n",
       " '00039.png',\n",
       " '00040.png',\n",
       " '00041.png',\n",
       " '00042.png',\n",
       " '00043.png',\n",
       " '00044.png',\n",
       " '00045.png',\n",
       " '00046.png',\n",
       " '00047.png',\n",
       " '00048.png',\n",
       " '00049.png',\n",
       " '00050.png',\n",
       " '00051.png',\n",
       " '00052.png',\n",
       " '00053.png',\n",
       " '00054.png',\n",
       " '00055.png',\n",
       " '00056.png',\n",
       " '00057.png',\n",
       " '00058.png',\n",
       " '00059.png',\n",
       " '00060.png',\n",
       " '00061.png',\n",
       " '00062.png',\n",
       " '00063.png',\n",
       " '00064.png',\n",
       " '00065.png',\n",
       " '00066.png',\n",
       " '00067.png',\n",
       " '00068.png',\n",
       " '00069.png',\n",
       " '00070.png',\n",
       " '00071.png',\n",
       " '00072.png',\n",
       " '00073.png',\n",
       " '00074.png',\n",
       " '00075.png',\n",
       " '00076.png',\n",
       " '00077.png',\n",
       " '00078.png',\n",
       " '00079.png',\n",
       " '00080.png',\n",
       " '00081.png',\n",
       " '00082.png',\n",
       " '00083.png',\n",
       " '00084.png',\n",
       " '00085.png',\n",
       " '00086.png',\n",
       " '00087.png',\n",
       " '00088.png',\n",
       " '00089.png',\n",
       " '00090.png',\n",
       " '00091.png',\n",
       " '00092.png',\n",
       " '00093.png',\n",
       " '00094.png',\n",
       " '00095.png',\n",
       " '00096.png',\n",
       " '00097.png',\n",
       " '00098.png',\n",
       " '00099.png']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os \n",
    "list=os.listdir(\"archive (1)\")\n",
    "list=list[0:100]\n",
    "list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12936\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "for i in list:\n",
    "    # Load the pre-trained face cascade from OpenCV\n",
    "    face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "\n",
    "    # Load the input image\n",
    "    image = cv2.imread(\"arcgive (1)/\"+i)\n",
    "\n",
    "    # Convert the image to grayscale\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Detect faces in the grayscale image\n",
    "    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
    "\n",
    "    # Iterate over the detected faces\n",
    "    for (x, y, w, h) in faces:\n",
    "        # Calculate the region of interest (ROI) for the face\n",
    "        roi_gray = gray[y:y + h, x:x + w]\n",
    "        roi_color = image[y:y + h, x:x + w]\n",
    "\n",
    "        # # Detect eyes within the face ROI\n",
    "        # reye_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_righteye_2splits.xml')\n",
    "        # reyes = reye_cascade.detectMultiScale(roi_gray, scaleFactor=1.1, minNeighbors=5, minSize=(20, 20))\n",
    "\n",
    "        # # Iterate over the detected eyes\n",
    "        # reyes=sorted(reyes,key=lambda row: row[2]*row[3],reverse=True)\n",
    "        # for (ex, ey, ew, eh) in reyes[0:1]:\n",
    "        #     # Calculate the coordinates relative to the entire image\n",
    "        #     eye_x = x + ex + ew // 2\n",
    "        #     eye_y = y + ey + eh // 2\n",
    "\n",
    "        #     # Draw a circle around the eye\n",
    "        #     cv2.rectangle(image, (x+ex, y+ey),(x+ex+ew, y+ey+eh),(0, 0, 0),2)\n",
    "            \n",
    "        #  # Detect eyes within the face ROI\n",
    "        # leye_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_lefteye_2splits.xml')\n",
    "        # leyes = leye_cascade.detectMultiScale(roi_gray, scaleFactor=1.1, minNeighbors=5, minSize=(20, 20))\n",
    "\n",
    "        # # Iterate over the detected eyes\n",
    "        # leyes=sorted(leyes,key=lambda row: row[2]*row[3],reverse=True)\n",
    "        # for (ex, ey, ew, eh) in leyes[0:1]:\n",
    "        #     # Calculate the coordinates relative to the entire image\n",
    "        #     eye_x = x + ex + ew // 2\n",
    "        #     eye_y = y + ey + eh // 2\n",
    "\n",
    "        #     # Draw a circle around the eye\n",
    "        #     cv2.rectangle(image, (x+ex, y+ey),(x+ex+ew, y+ey+eh),(0, 0, 0),2)\n",
    "        \n",
    "        # Detect eyes within the face ROI\n",
    "        eye_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_eye.xml')\n",
    "        eyes = eye_cascade.detectMultiScale(roi_gray, scaleFactor=1.1, minNeighbors=5, minSize=(20, 20))\n",
    "\n",
    "        # Iterate over the detected eyes\n",
    "        eyes=sorted(eyes,key=lambda row: row[2]*row[3],reverse=True)\n",
    "        for (ex, ey, ew, eh) in eyes[0:2]:\n",
    "            # Calculate the coordinates relative to the entire image\n",
    "            eye_x = x + ex + ew // 2\n",
    "            eye_y = y + ey + eh // 2\n",
    "\n",
    "            # Draw a circle around the eye\n",
    "            cv2.rectangle(image, (x+ex, y+ey),(x+ex+ew, y+ey+eh),(0, 0, 0),2)\n",
    "\n",
    "        # Detect the mouth within the face ROI\n",
    "        mouth_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_mouth.xml')\n",
    "        mouths = mouth_cascade.detectMultiScale(roi_gray, scaleFactor=1.1, minNeighbors=10, minSize=(40, 40))\n",
    "\n",
    "        # Iterate over the detected mouths\n",
    "        mouths=sorted(mouths,key=lambda row: row[2]*row[3],reverse=True)\n",
    "        for (mx, my, mw, mh) in mouths[0:1]:\n",
    "            # Calculate the coordinates relative to the entire image\n",
    "            mouth_x = x + mx + mw // 2\n",
    "            mouth_y = y + my + mh // 2\n",
    "            print(mw*mh)\n",
    "            # Draw a circle around the mouth\n",
    "            cv2.rectangle(image, (x+mx, y+my),(x+mx+mw, y+my+mh),(0, 0, 0),2)\n",
    "\n",
    "    # Display the image with the detected eyes and mouth\n",
    "    cv2.imshow(\"Facial Landmarks\", image)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
